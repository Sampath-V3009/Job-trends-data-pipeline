# ğŸ“Š Job Trends Data Pipeline

This project demonstrates a simple **ETL (Extract, Transform, Load)** pipeline built using **Python**, **Pandas**, and **SQLite**. The goal is to extract job salary data, clean and transform it, and store the refined data in a local database for future querying and analysis.

---

## ğŸ—ï¸ Project Structure

job-trends-data-pipeline/ â”‚ â”œâ”€â”€ ds_salaries.csv # ğŸ“¥ Raw dataset â”œâ”€â”€ etl_pipeline.py # ğŸ§¹ Extracts and cleans data â”œâ”€â”€ store_to_db.py # ğŸ—„ï¸ Loads data into SQLite DB â”œâ”€â”€ cleaned_jobs.csv # ğŸ“„ Cleaned output data â”œâ”€â”€ jobs_data.db # ğŸ›¢ï¸ SQLite database file â””â”€â”€ README.md # ğŸ“˜ Project documentation

---

## ğŸš€ Features

- Clean and map experience levels from codes to readable text
- Convert salaries from USD to INR
- Save the cleaned dataset to a `.csv` file
- Load data into a SQLite database for efficient storage
- Modular code for easy maintenance

---

## ğŸ“¥ Dataset Info

The raw dataset `ds_salaries.csv` contains job listing information with fields like:

- `work_year`
- `experience_level` (e.g., EN, MI, SE, EX)
- `employment_type`
- `job_title`
- `salary_in_usd`
- `employee_residence`
- `company_location`
- and more...

---

## ğŸ§¼ ETL Process

### Step 1: Extract & Transform (`etl_pipeline.py`)

- Reads the dataset from `ds_salaries.csv`
- Maps `experience_level` codes to human-readable text
- Converts salary from USD to INR using a sample conversion (Ã—83)
- Outputs cleaned data to `cleaned_jobs.csv`

### Step 2: Load (`store_to_db.py`)

- Reads the cleaned data from CSV
- Stores it into an SQLite database `jobs_data.db`
- Creates a table named `job_data`

---

## â–¶ï¸ How to Run the Project

1. **Run ETL Pipeline**

```bash
python etl_pipeline.py

2. Load Cleaned Data to SQLite



python store_to_db.py

3. Verify SQLite Data (Optional)



You can use tools like DB Browser for SQLite or Python scripts to inspect the database.


---

ğŸ§ª Sample Output

Cleaned CSV: cleaned_jobs.csv

SQLite DB Table: job_data



---

ğŸ’¡ Optional Enhancements

Add logging and exception handling

Convert pipeline into an Airflow DAG or Prefect flow

Add Jupyter Notebook for data exploration and visualization

Visualize top job trends using Matplotlib/Seaborn or Power BI

Add configuration via .env or .yaml file



---

ğŸš€ Future Improvements

Load data to cloud-based data warehouses (e.g., Amazon Redshift, Google BigQuery)

Use REST APIs for data extraction from live job boards

Automate the pipeline using Apache Airflow

Implement unit tests and CI/CD integration



---

ğŸ‘¤ Author

Sampath V
Aspiring Data Engineer
ğŸŒ LinkedIn Profile
## ğŸ”— Connect with Me
[![LinkedIn](www.linkedin.com/in/sampath3009
)



---

ğŸ“„ License

This project is licensed for personal and educational use. For commercial usage, please contact the author.

---

Let me know if you want this saved directly to a file (`README.md`) for you!
```
